# MCP Toolkit Architecture Explained

## ğŸ¯ Overview

Your MCP Toolkit is a **standalone Python application** that connects to various data sources through the Model Context Protocol (MCP). It does **NOT** require VS Code or VS Code Copilot to run.

## ğŸ—ï¸ Component Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER'S BROWSER                           â”‚
â”‚              http://localhost:7860                          â”‚
â”‚         (Gradio Web Interface - Chat UI)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â”‚ HTTP Requests
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PYTHON APPLICATION                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         ui_client.py (Gradio UI)                     â”‚  â”‚
â”‚  â”‚  - Handles chat messages                             â”‚  â”‚
â”‚  â”‚  - Displays responses                                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                     â”‚                                       â”‚
â”‚                     â†“                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚      agent_service.py (AI Agent)                     â”‚  â”‚
â”‚  â”‚  - Uses MCPAgent from mcp-use                        â”‚  â”‚
â”‚  â”‚  - Processes natural language queries                â”‚  â”‚
â”‚  â”‚  - Routes to appropriate MCP servers                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                     â”‚                                       â”‚
â”‚                     â†“                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚    mcp_manager.py (MCP Client Manager)               â”‚  â”‚
â”‚  â”‚  - Manages connections to MCP servers                â”‚  â”‚
â”‚  â”‚  - Loads mcp_config.json                             â”‚  â”‚
â”‚  â”‚  - Routes tool calls                                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â”‚ MCP Protocol (stdio/JSON-RPC)
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚            â”‚            â”‚             â”‚
        â†“            â†“            â†“             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL   â”‚ â”‚  GitHub  â”‚ â”‚Filesystemâ”‚ â”‚  LLM   â”‚
â”‚  MCP Server   â”‚ â”‚MCP Serverâ”‚ â”‚MCP Serverâ”‚ â”‚Providerâ”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Node.js       â”‚ â”‚ Node.js  â”‚ â”‚ Node.js  â”‚ â”‚OpenAI/ â”‚
â”‚ Process       â”‚ â”‚ Process  â”‚ â”‚ Process  â”‚ â”‚Anthropicâ”‚
â”‚               â”‚ â”‚          â”‚ â”‚          â”‚ â”‚ API    â”‚
â”‚ Connects to:  â”‚ â”‚Uses:     â”‚ â”‚Accesses: â”‚ â”‚        â”‚
â”‚ Adventureworksâ”‚ â”‚GitHub APIâ”‚ â”‚Local     â”‚ â”‚        â”‚
â”‚ Database      â”‚ â”‚with your â”‚ â”‚Files     â”‚ â”‚        â”‚
â”‚               â”‚ â”‚token     â”‚ â”‚          â”‚ â”‚        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”Œ Component Details

### 1. **MCP Servers** (Node.js processes)

Each server is a separate Node.js process that:
- Runs as a child process spawned by Python
- Communicates via **stdio** (standard input/output)
- Uses JSON-RPC protocol for requests/responses
- Provides tools/resources to the agent

**Your 3 MCP Servers:**

#### a) **PostgreSQL MCP Server**
```json
{
  "command": "npx",
  "args": ["@modelcontextprotocol/server-postgres", "${DATABASE_URL}"]
}
```
- **What it does**: Connects to your Adventureworks PostgreSQL database
- **Tools provided**: 
  - `query` - Execute SQL queries
  - `employees_database_schema` - Get schema info
  - `product_reviews_database_schema` - Get schema info
- **Connection**: Uses `DATABASE_URL` from .env file
- **No VS Code needed**: Runs independently

#### b) **GitHub MCP Server**
```json
{
  "command": "npx",
  "args": ["@modelcontextprotocol/server-github"],
  "env": {"GITHUB_TOKEN": "${GITHUB_TOKEN}"}
}
```
- **What it does**: Connects to GitHub API
- **Tools provided**:
  - List repositories
  - Create issues
  - Search code
  - etc.
- **Connection**: Uses `GITHUB_TOKEN` from .env file
- **No VS Code needed**: Direct GitHub API access

#### c) **Filesystem MCP Server**
```json
{
  "command": "npx",
  "args": ["@modelcontextprotocol/server-filesystem", "."]
}
```
- **What it does**: Provides file system access
- **Tools provided**:
  - Read files
  - List directories
  - Search files
- **Scope**: Current directory (`.`)
- **No VS Code needed**: Direct file system access

### 2. **Python Application Layer**

#### a) **mcp_manager.py** - MCP Client Manager
```python
from mcp_use import MCPClient

# Loads mcp_config.json
# Spawns Node.js MCP server processes
# Manages tool calls and responses
```

**How it works:**
1. Reads `mcp_config.json`
2. Substitutes environment variables from `.env`
3. Spawns each MCP server as a subprocess
4. Maintains stdio connections to each server
5. Routes tool calls to appropriate servers

#### b) **agent_service.py** - AI Agent Service
```python
from mcp_use import MCPAgent
from langchain_openai import ChatOpenAI

# Creates AI agent with LLM + MCP tools
# Processes natural language queries
# Returns responses
```

**How it works:**
1. Creates an LLM instance (OpenAI, Anthropic, etc.)
2. Creates MCPAgent with available MCP tools
3. Receives natural language query
4. Agent decides which tools to call
5. Executes tool calls via MCP servers
6. Returns formatted response

#### c) **ui_client.py** - Web Interface
```python
import gradio as gr

# Creates web-based chat interface
# Handles user messages
# Displays agent responses
```

**How it works:**
1. Creates Gradio chat interface
2. Runs web server on port 7860
3. Sends user messages to agent_service
4. Receives streaming responses
5. Updates chat UI in real-time

### 3. **External Services**

#### a) **LLM Provider**
- **OpenAI GPT-4** (in your case)
- Uses `OPENAI_API_KEY` from .env
- Provides natural language understanding
- Makes decisions about which tools to use

#### b) **Data Sources**
- **PostgreSQL Database**: Adventureworks on localhost:5431
- **GitHub API**: Via your personal access token
- **Local Filesystem**: Current directory

## ğŸ”„ Request Flow Example

**User asks: "Show me all tables in the database"**

```
1. Browser (http://localhost:7860)
   â””â†’ Sends message to Gradio UI

2. ui_client.py (chat method)
   â””â†’ Calls agent_service.stream(query)

3. agent_service.py
   â””â†’ Passes query to MCPAgent.stream()
   
4. MCPAgent (from mcp-use library)
   â”œâ†’ Sends query to LLM (OpenAI GPT-4)
   â”‚  "Which tool should I use for this?"
   â”‚
   â””â†’ LLM decides: "Use connect_to_mcp_server tool"
   
5. MCPAgent calls tool
   â””â†’ mcp_manager routes to postgres MCP server
   
6. PostgreSQL MCP Server
   â”œâ†’ Receives: query tool call
   â”œâ†’ Executes: SELECT table_name FROM information_schema.tables
   â””â†’ Returns: List of tables
   
7. Response flows back:
   PostgreSQL Server â†’ mcp_manager â†’ MCPAgent â†’ agent_service â†’ ui_client â†’ Browser
   
8. User sees: "Here are the tables: employees, product_reviews..."
```

## ğŸ†š VS Code Copilot vs Your Solution

### **Your Solution (Standalone)**
```
âœ… Runs independently - no IDE needed
âœ… Web-based UI (Gradio)
âœ… Connects to multiple MCP servers
âœ… Uses mcp_config.json for configuration
âœ… Can be deployed on a server
âœ… Accessible from any browser
âœ… Your own LLM API key
```

### **VS Code Copilot + MCP (Different approach)**
```
- Runs inside VS Code editor
- IDE-integrated experience
- Uses VS Code's configuration
- Requires VS Code to be open
- GitHub Copilot subscription
- Limited to coding tasks
```

## ğŸ”‘ Key Differences

| Aspect | Your Solution | VS Code Copilot MCP |
|--------|--------------|---------------------|
| **Requires VS Code?** | âŒ No | âœ… Yes |
| **Interface** | Web Browser | VS Code IDE |
| **Configuration** | mcp_config.json | VS Code settings.json |
| **MCP Servers** | Custom (postgres, github, filesystem) | VS Code managed |
| **LLM** | Your API key (OpenAI/Anthropic) | GitHub Copilot |
| **Use Case** | General Q&A, Data queries | Code assistance |
| **Deployment** | Can run on server | Desktop only |
| **Access** | Any browser | VS Code editor |

## ğŸ’¡ Your .env File Configuration

```bash
# LLM Provider
OPENAI_API_KEY=sk-proj-...   # â† Powers the AI responses

# Data Sources
GITHUB_TOKEN=ghp_...          # â† For GitHub MCP server
DATABASE_URL=postgresql://... # â† For PostgreSQL MCP server

# These connect to MCP servers, NOT to VS Code
```

## ğŸš€ Startup Process

When you run `./start.sh`:

```bash
1. Python 3.11 starts run.py
   â†“
2. Loads .env variables
   â†“
3. mcp_manager.initialize()
   â”œâ”€â†’ Reads mcp_config.json
   â”œâ”€â†’ Spawns: npx @modelcontextprotocol/server-postgres
   â”œâ”€â†’ Spawns: npx @modelcontextprotocol/server-github  
   â””â”€â†’ Spawns: npx @modelcontextprotocol/server-filesystem
   â†“
4. agent_service.initialize()
   â”œâ”€â†’ Creates OpenAI LLM client
   â””â”€â†’ Creates MCPAgent with MCP tools
   â†“
5. ui_client launches Gradio
   â””â”€â†’ Web server starts on port 7860
   â†“
6. Open http://localhost:7860 in ANY browser
   (Chrome, Firefox, Safari, etc.)
```

## ğŸ¯ Summary

**Your MCP Toolkit is:**
- âœ… **Standalone Python application**
- âœ… **Completely independent** from VS Code
- âœ… **Browser-based** web interface
- âœ… **Uses MCP protocol** to connect to data sources
- âœ… **Your own LLM** (OpenAI with your API key)

**You do NOT need:**
- âŒ VS Code installed
- âŒ VS Code Copilot subscription
- âŒ Any IDE at all

**You just need:**
- âœ… Python 3.11
- âœ… Node.js (for MCP servers)
- âœ… A web browser
- âœ… Your API keys (.env file)

The only connection to "VS Code Copilot" is that you **can** configure the LLM provider to use GitHub Models (which Copilot also uses), but that's just an alternative LLM provider - not required at all!
